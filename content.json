{"pages":[],"posts":[{"title":"Windows下Qt是如何实现串口通信的","text":"工作上的原因, 最近模仿Qt写了一个Windows下串口通信的实现, 在这过程中, 踩了不少坑, 所以写一篇文章总结一下. 首先需要明确的是, 在Windows下, 串口被抽象为文件, 对串口的读写, 实际上就是对文件的读写, 因此首先创建文件句柄. 123456789HANDLE handle = CreateFile( L\"COM1\", GENERIC_READ | GENERIC_WRITE, 0, NULL, OPEN_EXISTING, FILE_FLAG_OVERLAPPED, NULL); 使用CreateFile需要#include &lt;Windows.h&gt;. 该函数的具体用法可以参考MS的官方文档, 这里要表扬一下微软, 文档写的很详细, 但如果有使用实例就更好了.需要一提的是, 倒数第二个参数, FILE_FLAG_OVERLAPPED表示该文件是异步读写的, 如果设置为0, 则是只能同步读写. 如果打开成功, 我们会获得文件句柄handle, 通过它, 可以对这个串口进行一系列设置, 包括波特率, 校验位等. 12345678DCB dcb;bool rtn = GetCommState(handle, &amp;dcb);dcb.BaudRate = 115200;dcb.ByteSize = 8;dcb.StopBits = 0;dcb.Parity = 0;dcb.fParity = 0;rtn = SetCommState(handle, &amp;dcb); 设置完毕之后, 我们就要思考如何去读写了.我的需求是: 不设置额外的线程, 通过回调完成从串口拿回数据 不关心串口是否发送完毕, 发出去就行了 所以, 写串口十分简单: 12345char buff[64];PurgeComm(handle, PURGE_TXCLEAR); //清除之前发送的数据DWORD dwWrite = 0;OVERLAPPED overlapped;rtn = WriteFile(handle, buff, 64, &amp;dwWrite, &amp;overlapped); 这段代码里几乎没有什么返回值需要关心, 执行WriteFile也是异步的, 所以最终的发送交给操作系统了, 即使发送失败也不是代码的问题, 所以这样写就行了. 重头戏是读串口, 首先了解一下Qt是怎么做的: 1234graph TD Start([start]) --&gt; open --&gt; startAsyncComm[startAsyncComm: NtDeviceIoControlFile] -- callback --&gt; startAsyncRead[startAsyncRead: ReadFileEx] -- callback --&gt; completeAsyncRead --&gt; End([end]) completeAsyncRead -- more to read --&gt; startAsyncRead completeAsyncRead -- nothing to read --&gt; startAsyncComm 看起来很绕, 但简单来说, 主要涉及3个步骤: startAsyncComm:在这个函数中, Qt调用了一个ntdll.dll中的一个函数NtDeviceIoControlFile, 它的作用是, 接收串口驱动的可读事件, 将其加入系统的apc队列. 该函数需要的参数具体可以参考MS文档.值得一提的是, NtDeviceIoControlFile无法直接通过include头文件调用, 因为MS没有提供lib文件, 所以必须采取动态加载的方法. 这是第一个坑, 解决方法可以参考这个问题的回答.第二个坑是, 回调函数没有被调用. 这个问题是由于我没有设置CommMask.1SetCommMask(handle, EV_RXCHAR); 设置之后回调就正常了. startAsyncRead:startAsyncRead作为NtDeviceIoControlFile的回调函数在串口接收到信息后被调用. 在这个函数中, ReadFileEx系统函数被调用, 它的作用是, 异步读取串口数据, 其参数可以参考MS文档.文档告诉我们, ReadFileEx是异步的, 首先传入的文件句柄必须被设置为FILE_FLAG_OVERLAPPED, 这个我们已经在创建文件句柄的时候设置了, 这个没问题. 其次, 传给它的回调函数会在读到串口信息时被调用, 但因为它在NtDeviceIoControlFile回调函数中, 所以ReadFileEx被调用时, 一定是串口已经接收到数据了. 但是, 实际操作时, 我发现设置进ReadFileEx中的回调并没有被调用, 这是我遇到的第三个坑. 为什么呢, 我搜索了半天, 最终在CSDN的一个帖子中看到, ReadFileEx的回调只有当它读取到与设置参数中bytesToRead那么多数据后才会被调用, 经过实验, 我发现确实是这样, 但Qt源码设置的bytesToRead可是高达32768, 这与实际情况不符.最终还是因为忽略了在Qt源码中一个不起眼的调用:1234COMMTIMEOUTS currentCommTimeouts;ZeroMemory(&amp;currentCommTimeouts, sizeof(COMMTIMEOUTS));currentCommTimeouts.ReadIntervalTimeout = MAXDWORD;SetCommTimeouts(handle, &amp;currentCommTimeouts); 根据MS文档, 当ReadIntervalTimeout = MAXDWORD而其他值为0时, ReadFile会立即返回. 实验发现ReadFileEx会立即调用回调. 这一切就说得通了. completeAsyncRead:如果我们发现我们设置的buff被写满了, 那就说明串口中有可能还有数据没有读过来, 因此需要继续调用ReadFileEx来读取剩下的数据. 如果读完了, 那么这次对串口的读取就结束了, 可以准备下次的读取了, 因此调用startAsyncComm. 现在回头看那张流程图, 是不是觉得第一步有些多余, 明明ReadFileEx能做到对串口读取的回调, 为什么还要引入NtDeviceIoControlFile呢?我的理解是, ReadFileEx必须设置bytesToRead, 并且直到读满bytesToRead这么多的数据后才会去调用回调. 那么有人可能就会想到, 我把bytesToRead设置为1不就行了吗? 看似可行, 实际实验中造成了数据的丢失, 比如明明发送了”123456”, 却只收到了”16”. 丢失的行为还是随机的, 显然这样的结果是无法接受的. 弄清了Qt的实现, 我们就可以着手写自己的了, 以下是我的实现: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156#include \"stdafx.h\"#include &lt;string&gt;#include &lt;Windows.h&gt;#include &lt;iostream&gt;#include &lt;Winternl.h&gt;#ifndef IOCTL_SERIAL_WAIT_ON_MASK# define IOCTL_SERIAL_WAIT_ON_MASK \\ CTL_CODE(FILE_DEVICE_SERIAL_PORT, 18, METHOD_BUFFERED, FILE_ANY_ACCESS)#endifusing namespace std;char buff[1024];OVERLAPPED overlapped_;HANDLE handle;DWORD triggeredEventMask = 0;COMMTIMEOUTS currentCommTimeouts;typedef NTSTATUS(__stdcall *t_RtlNtStatusToDosError)( NTSTATUS Status);typedef NTSTATUS(__stdcall *t_NtDeviceIoControlFile)( IN HANDLE FileHandle, IN HANDLE Event OPTIONAL, IN PIO_APC_ROUTINE ApcRoutine OPTIONAL, IN PVOID ApcContext OPTIONAL, OUT PIO_STATUS_BLOCK IoStatusBlock, IN ULONG IoControlCode, IN PVOID InputBuffer OPTIONAL, IN ULONG InputBufferLength, OUT PVOID OutputBuffer OPTIONAL, IN ULONG OutputBufferLength);static void CALLBACK readDataCallback( DWORD dwErrorCode, DWORD dwNumberOfBytesTransfered, LPOVERLAPPED lpOverlapped);static VOID WINAPI qt_apc_routine( PVOID context, PIO_STATUS_BLOCK ioStatusBlock, DWORD reserved);static void CALLBACK ioCompletionRoutine( DWORD errorCode, DWORD bytesTransfered, OVERLAPPED *overlappedBase);static VOID WINAPI qt_apc_routine( PVOID context, PIO_STATUS_BLOCK ioStatusBlock, DWORD reserved);static void startAsyncComm();static void startAsyncRead();static void startAsyncRead(){ int rtn = ::ReadFileEx(handle, buff, 1024, &amp;overlapped_, readDataCallback);}static void CALLBACK ioCompletionRoutine( DWORD errorCode, DWORD bytesTransfered, OVERLAPPED *overlappedBase){ startAsyncRead();}static void CALLBACK readDataCallback( DWORD dwErrorCode, DWORD dwNumberOfBytesTransfered, LPOVERLAPPED lpOverlapped){ for (int i = 0; i &lt; dwNumberOfBytesTransfered; i++) { cout &lt;&lt; buff[i]; } startAsyncComm();}static VOID WINAPI qt_apc_routine( PVOID context, PIO_STATUS_BLOCK ioStatusBlock, DWORD reserved){ t_RtlNtStatusToDosError pfnRtlNtStatusToDosError = (t_RtlNtStatusToDosError)GetProcAddress(GetModuleHandle(L\"ntdll.dll\"), \"RtlNtStatusToDosError\"); const DWORD errorCode = pfnRtlNtStatusToDosError(ioStatusBlock-&gt;Status); const DWORD bytesTransfered = NT_SUCCESS(ioStatusBlock-&gt;Status) ? DWORD(ioStatusBlock-&gt;Information) : 0; const LPOVERLAPPED overlapped = CONTAINING_RECORD(ioStatusBlock, OVERLAPPED, Internal); (reinterpret_cast&lt;LPOVERLAPPED_COMPLETION_ROUTINE&gt;(context)) (errorCode, bytesTransfered, overlapped);}static void startAsyncComm(){ ZeroMemory(&amp;overlapped_, sizeof(OVERLAPPED)); const auto ioStatusBlock = reinterpret_cast&lt;PIO_STATUS_BLOCK&gt;( &amp;overlapped_.Internal); ioStatusBlock-&gt;Status = STATUS_PENDING; t_NtDeviceIoControlFile pfnNtDeviceIoControlFile = (t_NtDeviceIoControlFile)GetProcAddress(GetModuleHandle(L\"ntdll.dll\"), \"NtDeviceIoControlFile\"); const NTSTATUS status = pfnNtDeviceIoControlFile( handle, NULL, qt_apc_routine, reinterpret_cast&lt;PVOID&gt;(ioCompletionRoutine), ioStatusBlock, IOCTL_SERIAL_WAIT_ON_MASK, NULL, 0, &amp;triggeredEventMask, sizeof(DWORD));}int main(){ handle = CreateFile(L\"COM1\", GENERIC_READ | GENERIC_WRITE, 0, NULL, OPEN_EXISTING, FILE_ATTRIBUTE_NORMAL | FILE_FLAG_OVERLAPPED, // 0为同步，FILE_ATTRIBUTE_NORMAL | FILE_FLAG_OVERLAPPED为异步 NULL); cout &lt;&lt; \"handle: \" &lt;&lt; handle &lt;&lt; endl; DCB dcb; int rtn; rtn = GetCommState(handle, &amp;dcb); dcb.BaudRate = 115200; dcb.ByteSize = 8; dcb.StopBits = 0; dcb.Parity = 0; dcb.fParity = 0; rtn = SetCommState(handle, &amp;dcb); ::ZeroMemory(&amp;currentCommTimeouts, sizeof(currentCommTimeouts)); currentCommTimeouts.ReadIntervalTimeout = MAXDWORD; rtn = ::SetCommTimeouts(handle, &amp;currentCommTimeouts); rtn = ::SetCommMask(handle, EV_RXCHAR); startAsyncComm(); while (true) { SleepEx(INFINITE, true); cout &lt;&lt; \"recv data!\" &lt;&lt; endl; } return 0;} 代码其实不长, 但其中的坑却不少, 而且不是很容易解决, 很多问题不是很容易搜索出来, 必须自己去精准地定位问题然后自己查文档, 花了我不少时间, 不过最终跑通了还是小有成就感的. 2020/07/15","link":"/Windows%E4%B8%8BQt%E6%98%AF%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E4%B8%B2%E5%8F%A3%E9%80%9A%E4%BF%A1%E7%9A%84/"},{"title":"为网站添加ssl加密","text":"使用浏览器浏览网页的时候，在地址栏的左边会有一个符号加锁的表示启用了ssl，查看完整url的话可以看到是以https://开头的，而显示not secure的则是以http：//开头的。它们的区别在于，https传输的内容是加密的，而http则是以明文传输的，也就是说，如果有人在你的传输线路上抓包，走http包的内容别人可以一目了然，像username和password这种敏感信息，以及会暴露xp的搜索内容，也许就会被有心之人所利用。有兴趣的可以搜索一下中间人攻击，在这里就不展开讲了。现代的浏览器对于不加密的网址，往往都会给出提示。像firefox会弹出悬窗提示你该网站安全等级较低，chrome做的更绝，直接把页面block，除非你选择高级选项继续访问.对于搜索引擎排名优化而言，https的排名应该更有优势，至少谷歌是这样的。百度在早些年对https并不是很友好，甚至建议站长们提供http页面供它爬取. (source) 另外, 未加密的访问有可能遭到运营商的劫持。劫持的后果就是在你浏览的网页中, 加入它们的广告.劫持分为2种, DNS劫持和http劫持.DNS劫持可以理解为用户的请求去往了错误的DNS服务器进行查询解析，返回来的目的主机IP是运营商的中间服务器IP，访问该服务器会一致性的返回302，让用户浏览器跳转到预处理好的带广告的网页，在该网页中再通过 iframe 打开用户原来访问的地址。http劫持指在运营商的路由器节点上，使用旁路设备设置协议检测，一旦发现是HTTP请求，而且是html类型请求，则拦截处理。后续做法往往分为2种，1种是返回302让用户浏览器跳转到另外的地址，还有1种是在服务器返回的HTM 数据中插入js或dom节点（广告），浏览器收到302代码后就会跳转到错误的地址，或者修改了的HTML有广告，随后返回的真正数据到达后反而会被丢弃。参考 加密的好处大概就是以上这些，坏处就是加大了客户端和服务端的工作量，客户端会花更多的时间打开网页，服务端则会花费更多的资源去加解密。而且虽然加密了，但却不是完全无懈可击的，如果根证书就错了，那信任链整个就错了。 说了这么多，到底怎么给自己网站启用https呢。下面我说说我们的猴调网是怎么启用的。最开始，猴调网使用的是http，并且连域名都没有，访问是靠直接输ip的。在服务器端，nginx也只设置了默认80端口的服务器。要想使用ssl加密，就必须拥有一个证书，这个证书是受信任的机构颁发给你的。网上有很多攻略，比如从let’s encrypt获取免费的证书。但是，使用它的前提是，你有一个域名，不能一个裸的ip。那么，买个域名吧。在杭州的老马，深圳的老马和北京的老李之间，我最终选择了给深圳的老马一个坐公交车的机会。腾讯云的.club域名一块钱一年，跟白送差不多。另外，域名证书也能免费提供，所以直接用它的就行了。在下载它的证书之前，要先讲一下猴调网哪里需要用到这个证书。现在的猴调网的前端，不再是放在aws的服务器上了，我托管给了coding page，因为国内访问新加坡的服务器实在是又慢又不稳定。coding page上的域名可以绑定为www.houtiao.club以及houtiao.club这个主域名，让腾讯云解析到coding page原来的域名就可以了。并且，可以在coding page上直接设置为强制https访问，这是不需要我提供证书的，因为coding自己有。此时直接打开猴调网主页，就已经可以看到是ssl加密过的了。但是，当猴调网去调用后端api时，问题来了，后端并没有做ssl加密。这种情况下会产生两种后果，一是请求后端api的子页面不再被认定为是加密的了，另一种是chrome阻止了未加密的请求。这两种情况我都遇到了，无论那种，都不是我们想要的。所以，后端的api请求也必须使用https。之前没有申请域名走http的时候，我将后端的api接口直接暴露在公网上，前端只需要访问公网ip和端口就行了，这个后端是使用gunicorn部署的。这里，我改变了之前的做法。我没有再使用暴露在公网的api接口，而是使用了Nginx的反向代理，将公网api请求转发给内网的gunicorn端口，这样就将ssl加密的工作交给了Nginx。我们只需要在Nginx的服务器配置文件中配置监听443端口(https请求的默认端口)，启用ssl加密，并指定证书的路径。 1234567891011121314151617server { listen 443 ssl; server_name api.houtiao.club; ssl_certificate /home/ubuntu/upload/cert/Nginx/1_api.houtiao.club_bundle.crt; ssl_certificate_key /home/ubuntu/upload/cert/Nginx/2_api.houtiao.club.key; ssl_session_cache shared:SSL:1m; ssl_session_timeout 5m; ssl_ciphers HIGH:!aNULL:!MD5; ssl_prefer_server_ciphers on; location / { proxy_pass http://127.0.0.1:8000/; }} 这样，后端的代码就不需要做更改，前端的请求也使用了ssl加密。至此，猴调网就全面启用了https。","link":"/%E4%B8%BA%E7%BD%91%E7%AB%99%E6%B7%BB%E5%8A%A0ssl%E5%8A%A0%E5%AF%86/"},{"title":"npm安装速度过慢的原因","text":"如果普通的去搜索npm下载速度过慢之类的问题，无论百度或是谷歌，给出的答案都是你应该使用taobao的镜像源，然后列出了如何修改npm包源的方法。但这个方法并不适合我的情况。在尝试了各种方法后，我抱着试一试的心态用英文在谷歌上搜了下，得到了stackoverflow上的答案https://stackoverflow.com/questions/41524903/why-is-npm-install-really-slow。实际的情况确实是我的npm版本低了。我使用的是ubuntu18.04,apt维护的npm版本为3.5.2,使用命令sudo npm install npm@latest -g升级到npm的最新版本。目前，我的版本升级到了6.13.6。猴调博客的框架使用的是hexo，可以在网页的最底端看到。npm升级前花了若干小时都没有安装好，升级后也就是几秒钟的事。顺便我也把node升级了。 其实问题本身并不复杂，但中文的搜索结果给出的答案总是千篇一律，literally千篇一律，这其实挺有问题的。我搜索一些技术上的问题，不止一次地将问题转化成英文才有靠谱的答案。CSDN和简书上你抄我我抄你，哪怕翻译点英文的回来也好啊。笔者的技术水平也有限，猴调博客的内容也许不会那么高大上，但至少能保证每一篇都是原创，即使借鉴了别人的，也一定会有所注明。","link":"/npm%E5%AE%89%E8%A3%85%E9%80%9F%E5%BA%A6%E8%BF%87%E6%85%A2%E7%9A%84%E5%8E%9F%E5%9B%A0/"},{"title":"从公祭日各家行为看言论自由和自我审查","text":"这题目说实话起的有点大了，但想来想去也不知道究竟该取什么好，于是就现在这样吧。 解释一下题目中提到的一些名词。 公祭日指的就是2020年4月4号的国家公祭日，“为表达全国各族人民对抗击新冠肺炎疫情斗争牺牲烈士和逝世同胞的深切哀悼”举行的全国性哀悼活动。为此，国务院发布了公告，要求“全国和驻外使领馆下半旗志哀，全国停止公共娱乐活动”。 各家的行为指各门户网站（如百度）和其他偏娱乐性质的网站（如a站b站）将首页设置为黑白，直播网站停止所有直播并将网页设置为黑白，各游戏运营商关闭服务器等。 首先明确一点，我并不是说他们做的不对，或者我对此有什么怨言，他们都在以各自的方式表达对牺牲的医务工作者和逝世的病人的悼念，我的亲人中也有支援武汉的医务工作者，我深知他们为这次疫情做出了常人难以做到的付出，所以各家的行为我是理解并且赞同的。 与我相反，也有一些声音表达了对这些悼念行为的不满。在我看来，这样的声音也完全能够理解，我们对付出者和亡者已经做出的悼念行为，就像公告中说的，在10点的时候默哀，没必要弄到游戏和直播全部停止。但是，对于这些声音，无数的批判声音将他们淹没了，认为他们“脑子不正常”，“一天没游戏玩要了他们狗命”，“自私”。今天也有新闻说江苏网警处理了几名发表“不当言论”的网民，具体怎么处理，什么罪名，违反了什么法律，言论是什么，没有公布，在这里不做推测。 表达反对的声音真的错了吗？ 在传统观念中，死者为大，我们生者为了纪念他们，做出这一点小小的牺牲不算什么，不就是一天不看直播，不打游戏，只能看黑白的网站吗。但这样的想法其实是非常傲慢的，把所有人都以自己的情况来考虑。我在这里举一个在那篇新闻下面的评论里看到的例子，他说他是游戏代练，停一天的游戏让他那天没有饭吃。这样的人他抱怨两句，难道要骂他自私吗？至少我肯定不会。 所以对于反对的声音，如果没有站在他的角度思考过，我们不应该想当然地去反驳他，并且即使反驳他，也不应该上升到人身攻击的程度。我对于言论自由的解释，就是每个人都能为自己发声，并且不因为仅仅是立场不同让别人噤声。 题目中提到的最后一个词自我审查，是言论自由的反面。这个审查的目的不是让自身的言论有理有据，而是让言论符合别人的意愿。在这次悼念活动中，几乎所有人们熟知的网站，app都将自己设置成了黑白。希望他们都是出于自己的真心实愿。我害怕的一种场景是，当有一家没有将自己设置成黑白，有人会对此进行批评甚至举报。","link":"/%E4%BB%8E%E5%85%AC%E7%A5%AD%E6%97%A5%E5%90%84%E5%AE%B6%E8%A1%8C%E4%B8%BA%E7%9C%8B%E8%A8%80%E8%AE%BA%E8%87%AA%E7%94%B1%E5%92%8C%E8%87%AA%E6%88%91%E5%AE%A1%E6%9F%A5/"},{"title":"关于将猴调网前端部署到coding page遇到的问题","text":"构思猴调网的架构是Vue前端+Flask后端+MySQL数据库。之前所有的东西全部都部署在我的aws上，使用nginx作为前端服务器，gunicorn作为后端服务器。在实际使用中，后端只对内网开放，外部是无法进行api请求的。这样的架构其实对于一个个人小网站来说是绰绰有余的了，也完全能够正常访问。但由于aws服务器是在新加坡，这就导致国内的访问速度较慢。特别是猴调的前端有时候连github的仓库都连不上，打开猴调网有时候就是打不开。那么我作为运维，就要想办法了。通常，人们心血来潮想做个小网站又不想花钱买服务器部署的话，都会去使用github page或者coding page来发布自己的网站。在上述地方发布是完全免费的，只需要你把网页代码静态化上传到指定仓库就可以了。具体步骤可以去看github和coding自家的手册，coding手册不是很updated，但不在这里讨论了。显然，这样发布网站，你是不可能拥有后端的。但我有自己的服务器，我只需要前端去请求我服务器端的api就可以了，前端资源从国内的服务器下载到浏览器应该是比从新加坡来的快的。于是我就没有更改前端代码，直接发布到了coding page上，后端gunicorn配置对公网ip开放。遇到的第一个问题就是，api地址的错误。 问题一：api地址错误前端代码中，向后端发起请求是这样实现的 1this.axios.get('/api/material/list?name=' + this.searchName) axois默认的地址前缀就是我们网页部署的域名。所以整个api请求内容就是http://qztejm.coding-pages.com/api/material/list?name=searchName这不是我想要的，我需要将地址前缀修改为我后端服务器的ip+端口。这并不难解决，只要修改axios的默认地址前缀就好 1axios.defaults.baseURL = 'http://52.220.251.13:8000' 但是即使这样做，这个请求还是不对。在我的后端处理请求时，接受的请求内容中是不带“/api”的，像这样 1@APP.route('/material/list', methods=['GET']) 所以真正正确的请求内容应该是http://52.220.251.13:8000/material/list?name=searchName但之前前端部署在aws上明明可以正确发起请求，甚至使用的都是默认的80端口而不是后端开放的8000端口，为什么现在就不行了呢。这里其实是因为之前是部署在nginx服务器上，服务器的配置中有这么一条 12345678910111213location / { try_files $uri $uri/ @router; index index.html;}location /api { proxy_set_header X-real-ip $remote_addr; proxy_pass http://127.0.0.1:8000/;}location @router { rewrite ^.*$ /index.html last;} 可以看到，对/api路径的访问，nginx都帮我们转到http://127.0.0.1:8000/去了，所以在后端接收到的请求中，没有/api。那么，对于发布到coding page的版本，我们把/api去掉，路径也就正确了。在chrome中观察，请求确实没错了，但是产生了另一个问题。 问题二：CORS block所谓CORS，就是cross-origin source sharing，就是我明明访问的是A域名，却去请求了B域名。这看似没什么问题，前后端分离不就是这样么。但这会带来一个隐患：假如一个网页对其他各种需要登录验证的网站如微博、知乎、github等发起请求，如果恰好你已经处于登录的状态，那么这个网页就能获得你在登录状态能获得的资源。所以现代的浏览器，比如我用的chrome，就会默认有一个cors block。当浏览器发现cors行为时，会预先对该请求做验证，它会询问被请求的服务器是否允许这样的行为。一般来说，后端服务器只对自己信任的域名cors或者根本不允许。此时服务器会回复浏览器它信任的域名，供浏览器选择是否拦截这个cors请求。如果像我一样，没有在后端配置信任的域名，那么浏览器的询问得不到回答，于是对后端的请求就被拦截了。(https://dev.to/nicolus/what-you-should-know-about-cors-48d6)那么如何去配置呢？对于Flask来说，非常容易。 123456from flask_cors import CORSAPP = Flask( __name__)CORS(APP, resources={r'*': {'origins': r'http://qztejm.coding-pages.com/*'}}) r'*'表示对所有route配置都生效，'origins': r'http://qztejm.coding-pages.com/*'表示该域名是被我们允许的源域名。这样，重新部署一下后端就可以正常访问了。 coding page的问题解决了上面两个问题后，其实网页就已经可以正常访问了，但是，在刚部署完成时，我的访问特别不稳定，从浏览器里也看不出什么毛病。不过在我写到这里的时候，访问已经正常了，并且速度也确实超过了从aws的访问。但愿之后不会出什么问题。","link":"/%E5%85%B3%E4%BA%8E%E5%B0%86%E7%8C%B4%E8%B0%83%E7%BD%91%E5%89%8D%E7%AB%AF%E9%83%A8%E7%BD%B2%E5%88%B0coding-page%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98/"},{"title":"将他人的代码仓库添加到自己的代码仓库需要注意的问题","text":"这个问题是我在博客的框架hexo添加theme时遇到的。在hexo中添加theme一般是将别人做好的theme repo clone到自己本地的themes文件夹内。但是当你使用git clone时，一块下载下来的还有theme repo中的git文件。这就导致如果你自己博客本身也是一个git repo的话，你无法将这个theme纳入自己的git版本控制中。也就是说，这个theme其实相当于被忽略了。如果你尝试git add并push的话，你只会在远端对应分支看到一个空的文件夹。解决的方法很简单。在你add和push前，删除theme中一块被clone下来的git文件，也就是/.git，.gitignore等与theme无关的文件就可以了。对于已经上传了一个空文件夹的，笨办法就是删除git相关文件后，把theme挪出去传一次，再挪进来传一次就行了。","link":"/%E5%B0%86%E4%BB%96%E4%BA%BA%E7%9A%84%E4%BB%A3%E7%A0%81%E4%BB%93%E5%BA%93%E6%B7%BB%E5%8A%A0%E5%88%B0%E8%87%AA%E5%B7%B1%E7%9A%84%E4%BB%A3%E7%A0%81%E4%BB%93%E5%BA%93%E9%9C%80%E8%A6%81%E6%B3%A8%E6%84%8F%E7%9A%84%E9%97%AE%E9%A2%98/"},{"title":"技术进步服务了谁","text":"最近在看一本小说《诡密之主》，里面蒸汽朋克的背景提到了贝城的工厂主购买了新的纺织机器，导致了大批女工失业。在故事中，这些无产阶级生活贫穷，没有受过什么教育，拿着微薄的薪水，住着拥挤简陋的宿舍，可能只有一个睡觉的位置，没有存款，失业了就意味着没饭吃。当大批女工被辞退，这些人只能去寻求新的工作，这带来的后果就是找到工作的，薪酬更加微薄，因为劳动力变得更廉价了，没找到工作的，可能会选择离开，但这很难，因为没有存款，很可能饿死在路上，更多的是沦为妓女。无论何种结果，她们的生活都变得更加悲惨，而原因就是技术的进步取代了她们可以付出的劳动。这个背景让我想到了几年前在A站看到的一则新闻，当时无人机是一个比较火热的话题，京东正在部署实验线路用无人机运送货物。评论中有人说这是无用的，无人机是代替不了现在卡车司机的，一是成本高，二是会增加失业率。我和那人争论了一下，成本上来说，无人机在空中走的是直线，未必会比卡车成本更高，同时不必付出司机的劳务报酬，从失业率上来说，虽然无人取代了部分卡车司机，但无人机的生产研发维护会带来新的就业岗位，自然能带动就业率。但现在想来，这个关于就业率的驳论就有些站着说话不腰疼了，那些因为无人机失业的卡车司机可没办法走上无人机的就业岗位，他们是真的失业了，新技术的出现确实会伤害到他们，这是我以前从未想到的问题。 与大部分人一样，我也是从小接受的公立教育，在“唯物史观”的引导下，坚定地认为，技术的进步会带来生产力的进步，生产力的进步会带来物质的丰富，人民的生活水平会得到提高。从大的时间跨度上来看，历史确实是这样发展的，不要说是从工业革命开始，哪怕是从我出生开始算，我都能得到生活变好的结论。但是，从短时间上来看呢？我曾经在讲经济泡沫的文章中看到一则例子，当年纽约的出租车是需要有官方颁发的证件才能合法运营的，为了能成为合法的出租车司机，有些人会花大价钱从别人手中买来转让的证件，这个代价之大，可能跑很久的出租车也挣不回来，只能通过转让给别人才能收回成本。但后来像Uber和Lyft这样的网约车出现了，导致这个证件变得一文不值，那些最后接盘的人就成了泡沫的牺牲品。在我们讨论的话题中，人们的技能或者说受到的教育就好像是这个证件，一旦因为技术的进步而有更加廉价的替代品时，这些人的劳动价值就变得比这个替代品还要低，他们为了习得这些技能的时间成本就再也收不回来了，而去学习新的技能需要另外的时间成本，这对于他们来说，并不是一件容易的事情。回到小说的故事中，工厂引进新的机器，收益人是谁？很明显，是工厂主，是掌握生产资料的资产阶级，他们虽然花费了购进新机器的钱，却节省了需要付给工人的薪水，从长远来看，他们一定是获益的，否则他们就不会买这机器。所以在这次的技术进步中，资产阶级掌握了更先进的生产资料，提高了自己的生产力，间接地获得了工人们更多的剩余价值（因为劳动力过剩而带来的薪酬降低，当然，随着机器的普及，商品的价格也会相应降低，更新换代初期带来的高利润不会一直保持）。而工人呢，这样的技术进步不会给工人带来任何好处（除非你把未来商品降价也算进去），因为工人没有能力将这样的技术收为己用，并且反而被先进的技术所代替，文艺点的话来说，被历史的车轮碾了过去。所以，每当有新技术出现的时候，作为“工人”，不能想当然地认为这是好事，我们的生活将更加美好，我们得明确地意识到，新技术的出现意味着我所掌握的技术即将过时，如果我没有能力去掌握它，那我就会落后于时代而被淘汰。如果我有钱，我可以“买”来这种技术，这是一种掌握;如果我没钱，那我只能去学会这种技术，这并不是在炫耀什么，这只是跟上了时代的步伐，勉强不让自己被淘汰。我很庆幸我选择了计算机作为我的专业，这是时下的风口，同时互联网开放的环境让我拥有大量可以学习的资料，开源的精神让我可以接触很多最新的技术，这是很多传统行业所做不到的。母亲曾经劝我不要学计算机，她的理由是选择计算机就意味着需要不断学习新的知识，因为技术更新得太快了，这样会很累。而其他一些行业，像医生，越老越吃香。我妈不是医生，也许对医生的理解比较片面，但她的意思我明白，学一个需要经验积累的专业。这样确实不必时刻更新自己的知识，但需要在不断的实践中积累经验，从而提升自己的专业水平。这样不会总是忙于学习新技术新知识，但也有弊端，那就是年轻人没法出头，这个行业必然是被年长者所掌控的。诚然，我有一天也肯定会成为年长者，但前提是我不能改变我的专业，用时下流行的话来说，把路走窄了。年轻时必须埋头苦干，年长时成为行业的中流砥柱，这大概就是我母亲一辈的成长经历，那时候受环境所限制，连工作都是分配的，没什么好选择的。但现在毕竟不同，大家手头的工作都做了几年呢？而且，这样的行业，万一出现新技术革了他们的命，既得利益者可以吃吃老本，那埋头苦干的年轻人又将何去何从呢？所以，我可以简单地得出一个结论，谁掌握了进步的技术，那技术进步就服务了谁。贝城的女工们失去了工作因为她们的纺织技术被机器所取代，快递的卡车司机担心失去工作因为他们的驾驶技术可能会被无人机所取代。未来呢，你我手头的工作可能终有一天被新的技术所取代（我不想使用人工智能这一词，因为我觉得它现在被滥用了）。我们能做的，只有保持开放的心态，每当新技术出现时，不去挑刺地说它有诸多不好而抵制它，而是去学习它，掌握它，使用它，利用它去突破行业的壁垒，革那帮年长者的命，而不是被更年轻的人革了命。","link":"/%E6%8A%80%E6%9C%AF%E8%BF%9B%E6%AD%A5%E6%9C%8D%E5%8A%A1%E4%BA%86%E8%B0%81/"},{"title":"最近梯子很不稳定啊","text":"复工了。最近这个病毒是真的厉害，从小到大经历的全国性传染病中，这次是最严重的，影响到了生活的方方面面，工厂停工，学校停学，饭店关门，头发都没地方剪。作为一个在中型公司的打工仔，倒是没有体会到什么艰辛，但据说不少小公司有些撑不住了。讽刺的是，猴调的前端因为这次疫情没法出国度婚假，延迟了他的辞职，他的同事也因为类似的原因，延迟了辞职，反而维持了该公司的现状。在家办公了一周半，今天开始回公司上班，又体会到了早起的折磨。地铁上人仍然很少，随便坐，人们心理上似乎还是十分戒备病毒，主动与周围的人保持着距离，这在平日的深圳是无法想象的。另外一件事就是我的梯子最近不断被墙，上午改的端口或者ip下午就被封了，这也太严厉了。不知道有没有什么官方允许的渠道可以翻墙。频繁的更改ip导致我的猴调网api域名也失效了，真的是难受。","link":"/%E6%9C%80%E8%BF%91%E6%A2%AF%E5%AD%90%E5%BE%88%E4%B8%8D%E7%A8%B3%E5%AE%9A%E5%95%8A/"},{"title":"没想到真的会遇到要求别人让座的老人","text":"昨天早上做地铁去上班，7号线人不算很多，而且现在快过年了，人更少了些，但也没少到能有空位坐的程度，只是站在车厢里没那么挤而已。我戴着耳机一边听歌一边玩手机，所以周围的声音听得不是很清楚，但那个女孩的声音我听到了，她说她头疼，不想让座。我抬头，看到她面前站了一个胡子头发花白的老人。老人具体的年龄我也说不上来，可能六七十岁吧，胸前还挂了一个牌子，不知道写的什么。老人说话的声音不大，我戴着耳机加上地铁的环境，他说了什么我基本上没听见。女孩说完头疼之后，沉默了一会，不知道老人又说了什么，在下一站地铁到站时，女孩有些气愤的下车了，也不知道这站是不是她的目的地。老人就此坐下。但他似乎还不满足，指着座位上方贴的“爱心专座”的标志，问他边上坐的壮汉。壮汉没有两百斤估计也有一百八，十分响亮的回答，“不好意思，没注意。”老人也就没再说什么了。 如果那时坐在座位上的不是那个女孩，而是我，我会怎么做？我想，我大概会直接把座位让给那个老人。因为我坐着站着都差不多，挤地铁这么久了，站个几十分钟并没有什么，而且本来也是爱心专座，让个座位也算是响应标语的号召。虽然我会让座，但我并不认为女孩就应该让座。如果老人有要求别人让座的权利，那么女孩就应该也有拒绝让座的权利，即使那里是爱心专座，即使“尊老爱幼是中华民族的传统美德”。让座的行为不是天经地义的，也不是我国法律要求的，只是说我“尊老”，我体谅老人，我自愿自己不坐，给老人坐。这一行为的出发点是自愿。换句话说，如果我不愿意，我就能不让座，其他人不能强迫我让出我的座位。之前看新闻说公交车上老人让女孩让座，女孩不给，老人还动手。我都是笑笑，想着深圳应该没这样的老人。因为一来深圳老人并不多，能在深圳住下来的老人，应该家里都有矿，或者说他家本身就是个矿，心态可比年轻人好多了。二来深圳给我的人口素质印象还是很高的，从汽车会主动给行人让路就可见一斑，无锡能主动这样做的司机估计都不多。不过这样的老人，应该在哪都是少数吧。不知道我们这一辈老了之后会是什么样子的。","link":"/%E6%B2%A1%E6%83%B3%E5%88%B0%E7%9C%9F%E7%9A%84%E4%BC%9A%E9%81%87%E5%88%B0%E8%A6%81%E6%B1%82%E5%88%AB%E4%BA%BA%E8%AE%A9%E5%BA%A7%E7%9A%84%E8%80%81%E4%BA%BA/"},{"title":"猴调的诞生","text":"猴调博客确实很猴调，今天在公司搞了一天环境，hexo和webpack的依赖包下了很久最终还是没下好。回家之后windows的电脑同样是配置了taobao的镜像源，几秒钟就下好了。怀疑ubuntu18.04的网络配置真的有点bug，要么就是被我搞坏了。但总之，现在搞定了，至少博客正常上线了。这个猴调博客，是用来记录我们猴调网开发的过程的。猴调网用到的前后端框架，开发中遇到的问题，如何解决，以及部署上的问题，都会以博客的形式记录下来。但考虑到我们两个开发者有点猴调，这个博客很有可能只有少量的文章上传。另外，如果有灵感，可能会记录一些技术之外的事情。总之，能不断更新文章，哪怕文章不是很有营养，只是一些吐槽，也总比没有文章要来的好。","link":"/%E7%8C%B4%E8%B0%83%E7%9A%84%E8%AF%9E%E7%94%9F/"},{"title":"现代操作系统 第一章 引论","text":"为了督促自己读书，开个坑吧。现在在读的是《现代操作系统第四版》，作为一个没学过操作系统的coder，去了解一下这方面的知识还是挺有必要的。这本书很厚，看了下目录有五百多页，我可能看得不会面面具到，但我会把对我有用的一些基础知识记录下来，这个系列算是我对这本书的读书笔记吧。 引论部分讲的是对操作系统整体的概念。首先，什么是操作系统？ 原文中给出的不准确的定义是：操作系统是一种运行在内核态的软件。这说的让人一头雾水。内核态是计算机的一种运行模式，在该模式下，操作系统对具有对硬件的完全访问权，可以执行机器能够运行的任何指令。与之相对的是用户态，通常用户程序，也就是计算机使用者运行的各种软件，是跑在这个环境下的，用户程序所能使用的指令是内核态能用指令的子集。如果从操作系统的功能来描述的话，可能更好理解一些。如下图，操作系统就是在用户程序和硬件驱动之间的中间层。这个中间层，不光要提供接口，同时也要负责管理计算机的各种资源，比如计算资源处理器，文件资源硬盘，内存资源和各种IO设备。 接下来是操作系统的历史，从无到有到复杂，主要是因为硬件在不断的发展，标准在后来在逐渐设立。然后是计算机的硬件组成： 计算单元cpu即使是不太懂电脑的人也知道计算机中有这么一块芯片，主要负责计算机的逻辑和运算。从硬件上来说，一块cpu中，除了运算单元外，还有寄存器和缓存。其中寄存器是读写速度最快的，相应的容量也最小，然后是L1缓存，L2缓存，甚至L3缓存，它们的速度依次降低，容量依次变大。缓存的作用就是节省读内存的时间，即使我们知道，读内存已经比读磁盘快得多，但这还是要走内存总线，但缓存是在cpu内的，显然这快得多。图中前者为Intel的结构，L2缓存核间共享，后者为AMD的结构，L2缓存是独立的，各有优劣。另外，cpu有两种指令执行模式，流水线（pipeline）和超标量。流水线我之前就有了解过，cpu并非一次只加载一条指令，而是多条指令，这样能减少cpu取指令时的空闲时间。我去了解这个知识是因为发现在for循环中加入条件判断会影响执行速度，在google之后知道了是因为在if判断的时候，cpu并不会先去执行判断条件，而是会猜测结果构建流水线，如果cpu总是猜错，那么流水线在执行完毕后，还要回头再执行另一条分支。超标量这种方法就是新知识了，我没有深入了解过，不太清楚什么场景下会用到，它有点像交换机排队发包的感觉。 存储器在cpu中已经提到了，寄存器、缓存、内存和磁盘，它们速度一个比一个慢，容量一个比一个大，价格一个比一个便宜。操作系统对于它们的管理是非常重要的一个部分，也十分复杂，这部分会在后面的章节详细说明。 I/O设备I/O设备一般包括两个部分：设备控制器和设备本身。我们常用的鼠标键盘就是典型的I/O设备。有三种种策略去控制I/O设备，一是轮询，就是cpu不断问设备“你好了没有，你好了没有，你好了没有…”，显然，这样会占用cpu大量时间。二是中断，就是cpu给I/O设备布置任务，设备完成后发出中断通知cpu，在此期间cpu是未被占用的。第三种我不太熟悉，使用了DMA芯片，由该芯片管理中断。 总线我记得之前上学的时候还听过南桥北桥的概念，但在这里并未提及。从图中来看，总线其实就是连接cpu与其他设备的线，比较耳熟能详的有PCIe和USB。 BIOS在硬件上，它储存在一块ROM上，主要是用来做开机硬件检查和启动真正的操作系统的。 接下来是操作系统概念和抽象，这部分基本上就是全书的内容了。这里只是做一个介绍。进程进程的本质是正在执行的一个程序。与进程相关的一个重要概念是地址空间，进程可以进行读写，其内部存放有可执行程序，程序数据，程序堆栈。另外还有寄存器，打开文件清单等。进程基本上是容纳运行一个程序所需要的所有信息的容器。一个现代的操作系统需要处理多个进程运行的情况，我们知道cpu同一时间只能处理一条指令，为了让计算机能同时运行多个进程，操作系统必须在不同进程间来回切换以达到“同时”运行的效果。这里面的策略在这里就不展开了。 地址空间较复杂的操作系统允许在内存中同时运行多道程序，为了避免相互干扰，每个进程拥有自己的地址空间，这种机制是硬件形式的，但由操作系统掌控。虚拟内存可以让操作系统拥有比物理容量更大的内存，实际上是用硬盘上的空间映射到内存地址上。 文件文件系统其实是普通用户最能体验到不同操作系统区别的地方。Windows有cdef盘，我印象中物理上的硬盘可以分为Windows文件系统中不同的盘，但物理上不同的硬盘不能并为windows中的一个盘。Linux的文件系统是一个树，不管物理上有多少硬盘，都是在根目录下的。从用途上来说，文件系统提供了硬盘的抽象，用户程序不必去烦恼如何在硬盘中找到自己想要的数据，而是根据文件系统的目录，去读写文件。在Unix中，有特殊文件，通常是I/O设备，比如打印机，用户直接写这些特殊文件来操作设备。还有就是管道（pipe）。它是一种虚文件，用于进程间通信。 输入/输出每个操作系统都有管理其I/O设备的子系统，用来对计算机进行输入（键盘按键，鼠标点击），输出（显示器图像，音频）。 保护这里的保护指用户文件权限和其他计算机安全性问题。 系统调用接下来讲的是一些常见的系统调用，但这对于我一个初学者来说不是很友好，因为前面的概念都没有足够的了解，直接介绍了fork和read等系统调用，看了和没看差不多。这里就贴一张在UNIX和Windows中常见的一些系统调用吧。 需要特别说明的是，Windows一栏列出来的叫Win32 API，调用这些接口可能不全都是在内核态完成的，并且随着Windows版本的不同，它们的实现可能也会发生变化。 下面是操作系统结构的大类，我就捡我感兴趣的两个写一下。微内核微内核是相对与单内核或者叫宏内核来说的。它们之间的区别在于，前者将操作系统划分为小的、良好定义的模块，只有其中一个模块——微内核——运行在内核态。这样做的好处是，即使其他模块崩了，系统不会崩，而因为其微内核小，错误自然也会少。而后者虽然也可能会将操作系统划分成若干模块，但它们都会跑在内核态，这样的好处是效率高，系统服务没有用户态和内核态转换开销。大多数Linux都是宏内核操作系统，这符合它实用至上的原则。Windows和OS X是微内核操作系统，但它们并不纯粹，很多服务还是跑在内核态以此提高运行效率，所以我们能看到经典的Windows蓝屏。 虚拟机虚拟机这个词耳熟能详，我们常见的有VMware、VirtualBox和KVM。但它们似乎都只是应用程序一样的东西。早期第一代虚拟机，实际相当于操作系统，它跑在裸机上，向上层提供了若干台“虚拟”机。它不同于其他操作系统的地方是：这些虚拟机不是那种具有文件等优良特征的扩展计算机，而仅仅是裸机硬件的精确复制品。而第二代虚拟机，也就是我们上面提到的几个，实际上叫虚拟机管理程序，它们利用宿主操作系统的文件系统创建进程、存储文件。另外提到的是Java虚拟机JVM。学过Java的人知道，Java号称”Compile once, run everywhere.”Java之所以能做到这样，是因为Java代码编译成了JVM解释器可执行的代码，只要目标机器安装了JVM，JVM代码就可以运行。 第一章差不多就是这样，最后还有一些c语言相关的知识，就不在这里复述了。 2020/03/26","link":"/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20%E7%AC%AC%E4%B8%80%E7%AB%A0%20%E5%BC%95%E8%AE%BA/"},{"title":"现代操作系统 第二章 进程与线程","text":"进程进程的概念进程是操作系统提供的最古老也是最终要的抽象概念之一, 即使可以使用的cpu只有一个, 它们也具有支持(伪)并发操作的能力.现代计算机经常会在同一时间做许多事情, 比如编辑文档时接收邮件, 又比如上网课时偷偷打游戏:). 然而cpu在同一时间只能运行一个进程, 那些看似并行的行为, 其实只是cpu在快速地从一个进程切换到另一个进程, 使每个进程各运行几十或几百毫秒, 让我们产生并行的错觉. 这种快速的切换称作多道程序设计. 需要注意的是, 因为进程的执行会被cpu来回切换, 因此在写程序时, 我们不能去假设某条语句的运行时间.进程和程序之间的关系在我看来类似容器和内容的关系. 进程提供给了程序运行所需要的内存资源和运算资源, 程序规定了这些资源应该如何使用. 进程的创建4种主要事件会导致进程的创建: 系统初始化 正在运行的程序执行了创建进程的系统调用 用户请求创建一个新的进程 一个批处理作业的初始化 在UNIX系统中, 只有一个系统调用来创建新进程: fork. 这个系统调用会创建一个与调用进程相同的副本. 在调用之后, 父进程和子进程拥有相同的内存映像,同样的环境字符串和同样的打开文件. 通常, 子进程接着执行execve或一个类似的系统调用, 以修改其内存映像并运行一个新的程序.在Windows中, 一个Win32函数调用CreateProcess既处理进程的创建, 也负责把正确的程序装入新的进程. 无论哪种系统中, 进程创建后, 父进程和子进程拥有不用的地址空间. 因此进程修改在其地址空间中的字对其他进程是不可见的. 某些UNIX的实现可以让只读内存在进程间共享, 但可写内存一定是不共享的. 进程的终止进程的终止通常由下列条件引起: 正常退出(自愿) 出错退出(自愿) 严重错误(非自愿) 被其他进程杀死(非自愿) 当进程完成了它的工作, 会执行一个系统调用通知系统. 在UNIX中该调用是exit, Windows中是ExitProcess.杀死进程的调用在UNIX中是kill, 在Windows中是TerminateProcess. 进程的层次结构UNIX在初始化时, 一个称为init的特殊进程出现在启动映像中, 它读入一个说明终端数量的文件, 接着为每个终端创建一个新进程, 这些进程等待用户登录, 用户登录成功后, 就会执行一个shell准备接收命令, 从shell再去启动更多的进程. 因此, 这个系统中, 所有进程都是属于以init为根的一棵进程树.Winodws中没有进程层次的概念, 所有进程都是地位相同的. 进程状态 进程的三种状态分别是: 运行态(该时刻进程实际占用cpu) 就绪态(可运行, 但cpu正在被其他进程占用) 阻塞态(除非某种外部事件发生, 否则进程不能运行) 进程处在运行态还是就绪态是由调度程序决定的, 它是操作系统的一部分, 之后会详细讨论.阻塞态是因为进程调用了诸如pause等系统调用或等待外部输入时而进入的. 进程的实现 为了实现进程模型, 操作系统维护这一张表格, 即进程表, 每个进程占用一个进程表项. 为了能实现多个进程的切换, 进程表项中需要保存切换所需要的信息, 如上图所示. 线程线程相当于一个轻量的进程, 它也可以并行运行, 但不同的是, 线程之间共享地址空间.我们使用线程有以下若干理由: 许多应用场景会同时发生着多种活动, 引入线程会使我们的程序设计更加简单 线程比进程更轻, 在许多系统中, 创建一个线程比创建一个进程要快10~100倍 在存在大量计算和io的程序中, 使用线程能提高程序执行的速度 在多cpu系统中, 真正的并行有了实现的可能, 因此使用线程是有益的 经典的线程模型理解进程的一个角度是, 它用某种方法把相关的资源集中在一起. 进程拥有存放程序正文和数据以及其他资源的地址空间. 进程拥有一个执行的线程, 该线程中有: 一个程序计数器, 用来记录接着要执行哪一条指令; 若干寄存器, 用来保存变量; 一个堆栈, 用来记录执行历史(原文如此, 但我并不清楚什么叫执行历史, 通常堆栈保存的还是程序的数据).总的来说, 进程用于把资源集中到一起, 而线程则是在cpu上被调度执行的实体.线程给进程模型增加了一项内容, 即在同一个进程环境中, 允许彼此之间有较大独立性的多个线程执行. 在同一个计算机上并行运行的多个进程, 共享计算机的内存, 磁盘等资源, 而同一进程中的多个线程, 共享进程的地址空间和其他资源. 因此, 当我们的应用需要并行执行的时候, 尤其是并行任务需要数据交互的时候, 选择多线程是非常合适的. 创建和退出线程与进程差不多, 但有2点是不同的: 线程之间是平等的, 即使一个线程是由另一个线程创建出来的, 它们之间也不能认为是父子关系, 因为不会因为创建线程的退出而导致被创建的线程也退出 线程可以通过yield调用主动放弃cpu而让另一个线程运行. 进程不会这样做, 因为进程之间是竞争关系. 而线程这样做是因为它和其他线程是合作关系, 它们都是由程序设计者设计出来完成同一目标的. 通常线程的yield是为了等待其他线程完成某些任务. 在用户空间中实现线程 好处: 调度线程只需要在本地完成, 不需要陷入内核, 效率高 允许每个进程有自己定制的调度算法缺点: 不容易实现系统级阻塞, 比如让线程读取键盘输入, 如果让线程实际进行该系统调用就会停止所有线程 不容易处理页面故障. 所谓页面故障就是当程序不是一次性全部加载到内存中而在程序执行过程中跳转到了不在内存上的指令, 此时操作系统会去磁盘上找到这条指令(和它的邻居们)并加载到内存上. 因为内核感知不到用户级线程, 所以当某个线程触发页面故障时, 会导致整个进程被阻塞, 但实际上其他线程是可以运行的 在一个单独的进程内部, 没有时钟中断, 所以不能使用轮转调度的方式调度线程 在内核中实现线程好处和坏处与上面反一下. 混合实现编程人员决定使用内核线程还是用户线程, 内核只识别内核级线程, 并对其进行调度, 其中一些内核级线程会被多个用户级线程多路复用(这个描述就很模糊, 不明白) 调度程序激活机制听起来很拗口, 而且原文篇幅不少, 但总结起来就是, 内核去调用用户级的运行时系统(这个系统是用来调度线程的). 当线程触发了某些系统阻塞(上面介绍过的键盘输入和页面故障)后, 由内核去通知用户级的调度系统挂起该线程, 当阻塞过去, 也由内核去通知用户级的调度系统之前那个线程可以跑了. 当然, 如果线程没有引起系统阻塞, 那就跟用户级线程一样.好处显而易见, 坏处就是违反了分层次系统内在结构的概念, 简单说就是调用应该是单向的, 一方向另一方提供服务供其调用, 而不能双方互相调用. 听起来无伤大雅, 但其实很伤, 这对整个系统的架构产生了一定的混乱, 不够清晰, 为实现和维护增加了难度. 弹出式线程这是一种特殊的线程, 使用的典型场景是处理到来的消息. 当消息到达时, 创建一个处理该消息的线程, 因为它总是全新的, 因此可以为它优化创建过程, 使它能快速创建, 并能在内核中立即执行. 当然, 这么做的代价就是, 如果它出错会比用户级线程造成更大的损害. 使单线程代码多线程化除了要考虑读写问题外, 这一节还提醒我们有些库就不是为多线程设计的, 即线程不安全, 通常来说文档里都会写.以我的经验来说, 我更多的会去考虑多线程化的目的, 通过目的来决定需不需要多线程化, 和怎么去多线程化.首先, 有2中典型的需要多线程的情景: 执行某些阻塞调用, 如等待信号, 执行时间很长的计算等, 如果还有其他任务不能接受被阻塞, 如GUI界面, 那么这些调用应该被放到别的线程中 充分利用多核cpu来进行并行计算. 这里需要考虑的就是如何充分利用可用的核使计算时间最短. 显然无限多的线程不能带来无限短的计算时间, 计算过程本身也不一定能够如此完全的并行, 总有必须顺序执行的部分. 一般来说, 把可以并行的计算拆分到与核数一致或少于核数的线程中, 每个线程的计算过程相同, 只是数据不同. 当然, 如果每个线程的计算很少, 那就宁愿少用一些线程甚至不用多线程, 因为线程的创建和退出也是有开销的. 进程间通信有3个关于进程间通讯的问题: 进程如何把信息传递给另一个进程 如何保证进程间的操作不会打架 如何在需要时保证进程的执行顺序 对于第一个问题, 线程天然就解决了, 因为线程间共享地址空间. 第二和第三个问题在线程中也存在, 之后对于进程的问题讨论也同样适用于线程. 消息传递首先解决第一个问题.通过我查询的一些资料, 至少有以下几种手段可以实现进程间的消息传递: 本地TCP通信:很好理解, 两个进程一个做服务端, 一个做客户端, 握手后在本地同一个端口收发信息就行了. 管道:管道在UNIX中使用得非常普遍. 比如找到所有java进程1ps -ef | grep java |之前的ps -ef列出了所有进程信息, 之后的grep java是选择出含有java的信息. 前者的输出作为了后者的输入, 是典型的进程间通信. 12345678910111213141516171819202122232425262728#include&lt;stdio.h&gt;#include&lt;unistd.h&gt;int main(){ int fd[2]; // 两个文件描述符 pid_t pid; char buff[20]; if(pipe(fd) &lt; 0) // 创建管道 printf(\"Create Pipe Error!\\n\"); if((pid = fork()) &lt; 0) // 创建子进程 printf(\"Fork Error!\\n\"); else if(pid &gt; 0) // 父进程 { close(fd[0]); // 关闭读端 write(fd[1], \"hello world\\n\", 12); } else { close(fd[1]); // 关闭写端 read(fd[0], buff, 20); printf(\"%s\", buff); } return 0;} 这个是用c代码实现父子进程用管道通信3. 消息队列: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;sys/msg.h&gt;// 用于创建一个唯一的key#define MSG_FILE \"/etc/passwd\"// 消息结构struct msg_form { long mtype; char mtext[256];};int main(){ int msqid; key_t key; struct msg_form msg; // 获取key值 if((key = ftok(MSG_FILE,'z')) &lt; 0) { perror(\"ftok error\"); exit(1); } // 打印key值 printf(\"Message Queue - Server key is: %d.\\n\", key); // 创建消息队列 if ((msqid = msgget(key, IPC_CREAT|0777)) == -1) { perror(\"msgget error\"); exit(1); } // 打印消息队列ID及进程ID printf(\"My msqid is: %d.\\n\", msqid); printf(\"My pid is: %d.\\n\", getpid()); // 循环读取消息 for(;;) { msgrcv(msqid, &amp;msg, 256, 888, 0);// 返回类型为888的第一个消息 printf(\"Server: receive msg.mtext is: %s.\\n\", msg.mtext); printf(\"Server: receive msg.mtype is: %d.\\n\", msg.mtype); msg.mtype = 999; // 客户端接收的消息类型 sprintf(msg.mtext, \"hello, I'm server %d\", getpid()); msgsnd(msqid, &amp;msg, sizeof(msg.mtext), 0); } return 0;} 其中主要就是 123456789#include &lt;sys/msg.h&gt;// 创建或打开消息队列：成功返回队列ID，失败返回-1int msgget(key_t key, int flag);// 添加消息：成功返回0，失败返回-1int msgsnd(int msqid, const void *ptr, size_t size, int flag);// 读取消息：成功返回消息数据的长度，失败返回-1int msgrcv(int msqid, void *ptr, size_t size, long type,int flag);// 控制消息队列：成功返回0，失败返回-1int msgctl(int msqid, int cmd, struct msqid_ds *buf); 共享内存:系统提供的可以供多个进程读写的内存, 也很好理解, 不同的系统实现和接口不一样, 但思想是一样的, 用关键字来区分和访问不同的内存块. 竞争多个进程或线程访问同一块数据, 当时序不能保证时, 一定会带来读写问题, 即一个在读或者写, 但还没读写完, 就被另一个写了, 导致出错.对于这块数据, 我们称之为临界区. 为了避免发生临界区的竞争, 同时保证使用共享数据的并发进程能够正确和高效地进行协作, 我们的解决方案需要满足一下4个条件: 任何两个进程不能同时处于其临界区 不应对cpu的速度和数量做任何假设 临界区外运行的进程不得阻塞其他进程 不得使进程无限期等待进入临界区 忙等待的互斥 1234567891011121314151617181920#define FALSE 0#define TRUE 1#deinfe N 2int turn;int interested[N];void enter_region(int process){ int other; other = 1 - process; interested[process] = TRUE; turn = process; while (turn == process &amp;&amp; interested[other] == TRUE);}void leave_region(int process){ interested[process] = FALSE;} 以上是1981年 G. L. Peterson发现的互斥解法. 可以看到, 在进入临界区时, 如果另一个进程正在使用这个临界区, 那么就会一直陷入while (turn == process &amp;&amp; interested[other] == TRUE)循环, 这就是忙等待.虽然它可以保证不会有超过1个进程进入临界区, 但是这个while循环浪费了cpu的资源, 并不是我们钟意的解法. 睡眠与唤醒sleep和weakup是两个系统调用, 前者将进程挂起, 后者将挂起的进程唤醒使之可以继续执行.以生产者-消费者模型为例: 12345678910111213141516171819202122232425262728#define N 100int count = 0;void producer(void){ int item; while (TRUE) { item = produce_item(); if (count == N) sleep(); insert_item(item); count = count + 1; if (count == 1) wakeup(consumer); }}void consumer(void){ int item; while (TRUE) { if (count == 0) sleep(); item = remove_item(); count = count - 1; if (count == N - 1) wakeup(producer); consume_item(item); }} 缓冲区满了后, 调用sleep挂起生产者进程, 当缓冲区从空加入新数据, 唤醒消费者进程, 而消费者进程在缓冲区为空时挂起自己, 在缓冲区从满到不满时唤醒消费者进程.但它仍有问题, 就是count这个变量. 它仍有可能在不恰当的时机被修改导致生产者进程和消费者进程都休眠而无法唤醒. 例如在消费者进程检测到count为0时, 即将挂起自己, 但此时生产者将count修改为1, 并去唤醒消费者, 因为消费者本身就没有被挂起, 因此该唤醒被忽略, 但此时消费者仍然执行了sleep, 于是消费者永远被挂起, 生产者在写满缓冲区后也永远被挂起了.即使我们修改上面的代码, 在count不为0时就尝试去唤醒消费者, 在count小于N时就去唤醒生产者, 也不能正真解决这个问题, 因为只要count这个变量能够在任意时刻被修改, 就会遇到在消费者sleep之前耗尽缓冲区而不再发出wakeup调用的情况.所以, 我们需要保证, count的检测和sleep, wakeup之间是不可分割的. 这样就引入了下一节: 信号量1965年E. W. Dijkstra提出信号量, 它使用一个整形变量来累计唤醒次数. 一个信号量的值可以为0(表示没有保存下来的唤醒操作)或为正值(表示有一个或多个唤醒操作).Dijkstra建议设立两种操作: down和up.对一信号量执行down操作, 会检查其值是否大于0, 若大于0, 则将其减1; 若等于0, 则将进程挂起(有点像引用计数), 并在重新唤醒后再进行减1操作.对一信号量执行up操作, 会使其值加1. 如果1个或多个进程在该信号量上睡眠, 则由系统选择一个唤醒, 唤醒的进程会继续完成down操作. 互斥量如果不需要信号量的计数能力, 可以使用一个简化版本, 互斥量(mutex).互斥量是一个可以处于两种状态之一的变量: unlocked和locked. 典型的使用场景是当进程需要访问临界区时, 调用mutex_lock, 如果该互斥量是unlocked, 则对其加锁, 并进入临界区, 如果该互斥量是locked, 则进程被阻塞, 直到有进程调用mutex_unlock, 此时若有多个进程被该互斥量阻塞, 则随机选择一个进程唤醒, 并加锁.下面我们来看一下用pthread库中的互斥量来实现生产者消费者模型: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546#include &lt;stdio.h&gt;#include &lt;pthread.h&gt;#define MAX 1000000000pthread_mutex_t the_mutex;pthread_cond_t condc, condp;int buffer = 0;void *producer(void *ptr){ for (int i = 1; i &lt;= MAX; i++) { pthread_mutex_lock(&amp;the_mutex); while (buffer != 0) pthread_cond_wait(&amp;conp, &amp;the_mutex); buffer = i; pthread_cond_signal(&amp;condc); pthread_mutex_unlock(&amp;the_mutex); } pthread_exit(0);}void *consumer(void *ptr){ for (int i = 1; i &lt; MAX; i++) { pthread_mutex_lock(&amp;the_mutex); while (buffer == 0) pthread_cond_wait(&amp;condc, &amp;the_mutex); buffer = 0; pthread_cond_signal(&amp;condp); pthread_mutex_unlock(&amp;the_mutex); }}int main(int argc, char **argv){ pthread_t pro, con; pthread_mutex_init(&amp;the_mutex, 0); pthread_cond_init(&amp;condc, 0); pthread_cond_init(&amp;condp, 0); pthread_create(&amp;con, 0, consumer, 0); pthread_create(&amp;pro, 0, producer, 0); pthread_join(pro, 0); pthread_join(con, 0); pthread_cond_destroy(&amp;condc); pthread_cond_destroy(&amp;condp); pthread_mutex_destroy(&amp;the_mutex);} pthread_cond_wait会让当前线程阻塞并解锁互斥量, 而pthread_cond_signal则会唤醒前者并让前者的互斥量加锁.至此, 我们的生产者-消费者模型终于能用了. 管程管程(monitor)是一个语言概念, 它保证在管程中的一段代码在同一时间只能有1个活跃进程, 这是由编译器保证的. 然而c语言并不支持管程, 我也不清楚哪种语言有这个特性, 所以就不详细介绍了. 屏障屏障(barrier)是进程组用来同步的机制. 这个在并行计算中使用得非常普遍, CUDA中也有这个概念. 比如我们要进行2次矩阵乘法运算, 我们将矩阵乘法拆分成一个进程或线程计算一行和一列的点乘. 那么我们就需要在第一次乘法和第二次乘法之间设置一个屏障, 当第一次乘法的所有进程或线程计算完毕后才能再开始第二次乘法运算, 如果不这么做, 第二次计算就会使用错误的值. 避免锁虽然锁给我们在多进程和线程合作中带来的方便, 但我们也要知道, 使用锁是有代价的. 为了性能, 我们应该尽量避免使用锁.有时候, 我们在读数据的时候, 并不在意当前读到的值是否是最新的, 只要是正确和完整的值就能接受. 比如周期备份的日志, 也许正在有一条新的日志写进来, 但这一次的备份没必要去等它, 因为它在下个周期时总能被备份. 但尽管不需要等它, 我们在备份时, 不能保存一条写了一半的日志. 在这种情况下, 我们可以使用读-复制-更新(Read-Copy-Update, RCU)的方法. 写日志的进程在写完一条数据之前不会修改备份进程读到的数据, 直到写完一条, 将其更新到实际日志中, 这个更新操作是原子的, 这比使用锁的代价小多了. 调度当2个或更多的进程处于就绪状态时, 我们就需要选择下一个要运行的进程, 完成选择工作的这一部分称为调度程序(scheduler), 该程序使用的算法称为调度算法. 进程行为有些进程花费了绝大多数时间在计算上, 有些则在等待I/O上, 前者我们称为计算密集型, 后者称为I/O密集型. 有必要指出, 随着cpu变得越来越快, 更多的进程倾向为I/O密集型, 这是因为cpu的改进比磁盘改进快的多, 这导致未来对I/O密集型进程的调度处理似乎更为重要. 基本原则是, 如果需要运行I/O密集型进程, 那么就应该让它尽快得到机会, 以便发出磁盘请求并保持磁盘始终忙碌. 何时调度有关进程调度处理的一个关键问题是何时进行调度决策, 有以下几种情形: 在创建一个新进程后 在一个进程退出后 当一个进程阻塞时 当一个I/O中断发生时前3个比较好理解, 这里说明一下第4个. I/O中断发生在I/O设备完成工作时, 此时被阻塞的等待该I/O的进程从阻塞变为了就绪, 那么调度程序就要决定是继续阻塞这个进程还是挂起当前线程唤醒这个阻塞的进程. 调度算法分类 非抢占式:一个进程会一直运行到它自己退出或被阻塞, 即使它运行了若干小时, 也不会被强迫挂起, 在一个进程退出或被阻塞时, 通常按照优先级在进程队列里选择优先级最高的进程运行 抢占式:每个进程只能运行一小段固定时间(时间片), 如果该时间结束时进程还在运行, 则该进程会被挂起, 调度程序会挑选另一个进程运行. 这么做的前提是时钟中断发生在时间片结尾. 如果没有时钟, 那么就只能使用非抢占式的方法了. 对不同的环境需要使用不同的调度算法. 我们大致把环境分为3种: 批处理:批处理系统在商业领域仍广泛应用, 用来处理薪水册, 存货清单, 帐目收入等周期性作业, 它们不会有用户不耐烦地在终端旁等待. 因此, 非抢占式算法, 或对每个进程都有长时间周期的抢占式算法通常都是可接受的. 这个处理方法减少了进程的切换从而改善了性能. 交互式在交互式用户环境中, 为了避免一个进程霸占cpu, 抢占是必须的, 如服务器和我们日常所用的pc 实时在有实时限制的系统中, 抢占有时是不需要的, 因为进程了解它们可能会长时间得不到运行, 所以通常很快地完成各自的工作并阻塞. 实时系统通常是专用的, 只运行用来推进现有应用的程序, 这些程序的行为都是可预测的, 因此可以不需要抢占. 调度算法的目标 批处理系统中的调度 先来先服务(first-come first-served)优点: 易于理解, 便于实现缺点: 未对不同类型的进程进行调度优化, 吞吐量, 周转时间, cpu利用率均不是最优 最短作业优先(shortest job first):当可以预知进程运行时间时, 优先运行时间最短的进程优点: 当所有作业都可运行的情形下, 周转时间最优缺点: 需要能够预知进程的运行时间. 最短剩余时间优先(shortest remaining time next)抢占式的最短作业优先, 调度程序总是选择剩余运行时间最短的进程运行优点: 当有新来的短时间进程就绪, 比最短作业优先的方法周转时间更短缺点: 需要能够预知进程的运行时间. 交互式系统中的调度 轮转调度:每个进程被分配一个时间段, 称为时间片(quantum), 当进程在时间片结束时还未运行完毕, 则强制剥夺cpu并分配给另一个进程.我们知道进程的切换是有代价的, 假设切换进程需要1ms, 而我们的时间片长度为4ms, 则cpu将会有20%的时间浪费在了管理开销上, 这显然是不划算的(想起了苏妈说的MIT的phd给哈佛的mba打工). 但如果时间片设定过长, 则进程的等待时间也会变长, 这将会引起用户的不满, 这也是我们不愿意看到的.所以结论就是, 时间片太短会导致过多的进程切换, 降低了cpu的效率, 而太长的话则又会引起交互请求响应时间变长. 将时间片设为2050ms通常是一个比较合理的折中. (原书似乎是2015年出版的, 这个”2050ms”对于现在来说我也不知道合不合适) 优先级调度: 图中给出了一个有4类优先级的系统, 它会按照优先级的高低在同级内实行轮转调度, 当优先级高的执行完毕后, 才会轮到优先级低的进程. 显然, 如果不偶尔对优先级进行调整, 低优先级的进程很可能会产生饥饿现象. 多级队列(Compatible Time Sharing System):为了减少进程切换带来的损耗, 多级队列策略在进程被切换后再次执行时分配给该进程较之上次双倍的时间片, 并降低优先级. 这样做可以兼顾响应时间, 为那些运行时间短的进程能够尽快完成.对于那些刚开始运行一段长时间, 而后来又需要交互的进程, 为了防止其永远处于被惩罚状态, 在终端上有回车键按下时, 则属于该终端的所有进程就都被移到最高优先级. 但这样做其实有被滥用的风险, 因为用户有可能会发现, 只要在自己的终端每隔几秒敲一下回车键就可以大大提高响应时间, 如果这个经验被广泛传播出去, 那么这个策略可能就失效了. 保证调度:向用户作出明确的性能保证, 比如用户将获得cpu处理能力的1/n. 彩票调度:其基本思想是为进程提供各种系统资源(如cpu时间)的彩票. 一旦需要做出一项调度决策时, 就随机抽出一张彩票, 拥有该彩票的进程获得该资源. 实时系统中的调度实时系统是一种时间起着主导作用的系统. 典型地, 一种或多种外部物理设备发给计算机一个服务请求, 而计算机必须在一个确定的时间范围内恰当地做出反映. 例如cd播放器, 病人监护装置, 飞机的自动驾驶系统, 自动化工厂中的机器人控制. 在所有的这些例子中, 正确的但是迟到的应答往往比没有还要糟糕. 实时系统通常可以分为硬实时和软实时. 前者必须满足绝对的截止时间, 后者对错失截至时间有一定的容忍性. 经典的IPC问题哲学家就餐问题这个问题在1965年由Dijkstra提出(又是他!). 这个问题可以简单地描述如下:5个哲学家围坐在一张圆桌周围, 每个哲学家面前都有一盘通心粉, 需要两把叉子才能进餐, 相邻的2个盘子之间放有1把叉子. 哲学家有2中活动状态: 吃饭和思考. 当哲学家饿了的时候, 他就会试图去取其左边和右边的叉子, 每次拿1把, 但不分次序, 如果拿到了2把, 就可以吃饭. 需要解决的问题是: 能为每一位哲学家写一段描述其行为的程序并保证不会死锁吗? 从那时起, 每个发明新的同步原语的人都希望通过解决哲学家就餐问题来展示其同步原语的精妙之处. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748#define N 5#define LEFT (i+N-1)%N#define RIGHT (i+1)%N#define THINKING 0#define HUNGRY 1#define EATING 2typedef int semaphore;int state[N];semaphore mutex = 1;semaphore s[N];void philosopher(int i){ while (true) { }}void take_forks(int i){ down(&amp;mutex); state[i] = HUNGRY; test(i); up(&amp;mutex); down(&amp;s[i]);}void put_forks(int i){ down(&amp;mutex); state[i] = THINKING; test(LEFT); test(RIGHT); up(&amp;mutex);}void test(int i){ if (state[i] == HUNGRY &amp;&amp; state[LEFT] != EATING &amp;&amp; state[RIGHT] != EATING) { state[i] = EATING; up(&amp;s[i]); }} 以上的这段代码是哲学家就餐问题的一种解法, 它保证一个哲学家只有在两个邻居没有进餐时才允许进入到进餐状态. 读者-写者问题简单来说就是需要实现当一个进程在写的时候不允许其他的读写, 但一个进程在读的时候可以允许其他进程读.这个问题就不给出代码实现了, 很多框架都提供这样的读写锁, 或者直接对自己的数据结构实现了读写锁. 第二章差不多就是这些了, 内容可真不少, 不过也难怪, 进程和线程是操作系统中非常基础但十分重要的概念.某些编程语言中(如Go)还有协程的概念, 它是完全在用户态中由应用程序自己实现的伪并行. 所以它确实不属于操作系统的范畴. 之后我可能不会按顺序读下去了, 我会挑选我感兴趣的章节继续记录. 2020/06/17","link":"/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-%E7%AC%AC%E4%BA%8C%E7%AB%A0-%E8%BF%9B%E7%A8%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B/"},{"title":"使用CMake搭建C++项目","text":"CMake是什么官网cmake.org是这么描述的：CMake is an open-source, cross-platform family of tools designed to build, test and package software. CMake is used to control the software compilation process using simple platform and compiler independent configuration files, and generate native makefiles and workspaces that can be used in the compiler environment of your choice. The suite of CMake tools were created by Kitware in response to the need for a powerful, cross-platform build environment for open-source projects such as ITK and VTK. 翻译过来就是：CMake是开源、跨平台工具家族的一员，用来生成、测试和打包软件。CMake通过使用简易的平台和独立于编译器的配置文件，根据你的选择来生成编译环境需要的原生的makefile和workspace，并以此控制软件的编译过程。CMake套件由KitWare打造，满足了开源项目如ITK和VTK对一款强大的、跨平台的构建环境的需求。 简单来说，CMake就是一款开源且跨平台的编译环境构造工具，我们可以用它为自己的C++项目编写项目配置文件，并在不同的平台，如Windows、Mac和Linux，生成所需的编译配置和环境。 为什么要用CMakeC/C++项目的编译过程大体分为2步，编译和链接。编译就是将源文件生成目标文件，链接就是将源文件中的引用部分转换成目标文件中实际实现的地址（这里实际简略了一些步骤，我没有展开）。CMake的配置文件CMakeLists.txt里面就规定了源文件（对应第一步）和所需的第三方头文件和库文件（对应第二步）。这里大家可能就看出来了，CMake实际上做了Visual Studio的项目文件（Windows下）和makefile（unix下）的工作。没错，CMake会根据你的平台生成对应的文件，这样我们就只需要维护一份项目配置文件就可以做到多平台通用了。 在我个人经历的团队合作项目中，Visual Studio的项目配置文件总会在分支合并时遇到冲突，这通常是因为不同开发者本地路径不同导致的。即使使用了相对路径，也不能完全避免冲突，这就很令人抓狂。而CMakeLists作为通用的项目配置文件，使用find_package来配置第三方库可以有效避免路径带来的冲突问题，并且环境配置一目了然，赏心悦目。 浏览一下Github上的开源项目，只要是跨平台应用，绝大多数都提供了CMakeLists作为配置文件，方便不同平台的用户使用，可以说是主流的配置工具，学会使用是很有必要的。 如何使用CMake先上一个CMakeLists例子，我们来逐句解释 123456789101112131415161718192021222324252627cmake_minimum_required(VERSION 3.8)message(STATUS &quot;Working in Solution Dir&quot;)find_package(Qt5Core)add_definitions(-Dxxx)project(project_name)include_directories(include)file(GLOB lib_header /lib/*.h)file(GLOB head_files /include/*.h)list(APPEND head_files lib_header)add_subdirectory(sub_directory)qt5_add_resources(QRC_FILE ${PROJECT_DIR}/Resources/hawkeye_pro.qrc)set(EXECUTABLE_OUTPUT_PATH ${SOLUTION_DIR}/build/bin)set(CMAKE_INCLUDE_CURRENT_DIR ON)set(CMAKE_AUTOMOC ON)set(CMAKE_AUTORCC ON)add_library(lib_name SHARED ${source_files})target_link_libraries(lib_name ${dependent_libs} Qt5::Core)add_executable(exe ${source_files}) cmake_minimum_requiredCMake版本最低要求，根据实际情况来定。message打印信息，STATUS加不加都行，输出格式不同而已。当生成出错时，可以根据打印信息的位置定位问题。find_package查找打包的软件，这要求该软件在系统路径下，并且它发布时带有后缀名.cmake的配置文件。.cmake文件记录了本地该软件的安装情况，find_package会将这些信息告诉编译器，这可比写makefile和在vs中设置include和库文件简洁多了。add_definitions添加宏定义project项目名include_directories头文件路径，通过find_package配置的头文件不需要在这里重复了file将众多文件定义为一个变量list链表操作add_subdirectory加入一个子项目路径，要求该路径下含有一个CMakeLists文件。子项目会继承父项目的所有变量，但不会影响父项目。执行方式是递归的。qt5_add_resourcesQt项目的特殊操作，编译资源文件，项目不含Qt可以忽略。set定义变量，这里需要说明的是，CMake有很多预先定义好的变量，这个需要查阅文档。CMAKE_AUTOMOC和CMAKE_AUTORCC是Qt相关的变量，这里就不详细展开了。add_library定义生成的库文件，包括名字、静态库或动态库、源文件是哪些等。target_link_libraries需要链接的第三方库add_executable定义生成的可执行文件，包括名字、源文件是哪些等。 这里所列出的是一些十分常用的命令，还有一些比较冷门的骚操作没有写进去，这些命令配置基本可以满足一般的项目需求了。 写好CMakeLists之后，新建一个build文件夹（不新建也行，看的不闹心就行），在build路径下执行 1cmake ${your_cmakelists_path} 这样你就会得到一个makefile（unix下）或vs的sln文件（Windows）下。我强烈建议在Windows下使用CMake的Gui程序来生成sln文件，这样可以更清楚的控制生成的vs项目的版本和其他一些配置。 总结CMake是主流的C++跨平台编译环境配置工具，简单易用，即使自己的项目不用，使用别人开源的项目也会用到，学习一下基本用法肯定没错。","link":"/%E4%BD%BF%E7%94%A8CMake%E6%90%AD%E5%BB%BAC-%E9%A1%B9%E7%9B%AE/"},{"title":"白嫖jsDelivr作为自己网站的cdn","text":"jsDelivr是一个免费的，为开源代码提供内容分发服务的服务商。官网上它自己的描述是：所谓cdn，就是Content Delivery Network内容分发网络的缩写。它的主要功能是，将你提供的内容缓存在服务商提供的不同的服务器中，就好像物流的存储仓库一样，深圳生产的手机，原厂有库存，北京的仓库有库存，广州的顾客下订单就从深圳走，天津的顾客下订单就从北京的仓库走。好处显而易见，快的同时还分担了流量的压力。通常来说，cdn服务商会根据流量或者缓存大小等收取费用，如果我们只是凭借自己的兴趣搭了个小网站，肯定能白嫖尽量白嫖啊。所以，免费的jsDelivr是非常合适的选择。那么，怎么使用呢？ jsDelivr不需要你上传任何内容，它天然提供对npm，github和wordpress上开源资源的内容分发。以大家比较熟悉的github举例，假设你有一组图片需要使用jsDelivr的加速，你需要在github上创建一个public的repo，将你的图片上传。当你的网站中需要这张图片时，使用 1https://cdn.jsdelivr.net/gh/${user}/${repo}@${branch}/${file} 就可以享受到加速了。其中${user}是你的github用户名，${repo}是你的项目名，${branch}是项目分支的名字，如果使用项目的Release包，就填Release的版本号，${file}就是这个repo下的文件名了。首次使用十分便利，立竿见影。但需要注意的是，如果你想修改文件内容，虽然图片一般不会修改，但有时我们加速的不是图片，而是js代码，当代码修改，即使推送到了github上的相应分支，jsDelivr也不会即使更新它的缓存，目前，官网也没有提供清空或者更新缓存的接口，查阅网上的资料，大多都说是随缘更新。我看到有人说将分支名称改为latest可以做到及时更新，实测下来并不可以。如果使用的是Release包，这个问题会小些，因为改变文件内容意味着必须发布一个新的Release版本，引用相应文件的地址也必须改变。加速npm包与加速github上的文件类似，使用 1https://cdn.jsdelivr.net/npm/${package}@${version}/${file} 其中${package}是在npm上的包名，${version}是版本号，${file}就是包内的文件了。发布npm包其实比创建github上的项目还要简单，首先登陆npm的官网注册一个账号，并通过邮箱验证。然后在已经安装过npm情况下，通过npm login登陆，使用npm init创建包的配置文件，包括包名，版本，描述，作者，邮箱等，最后使用npm publish就可以将该路径下的文件打包发布了。作为白嫖的cdn，除了更新缓存存在缺陷外，已经挑不出什么毛病了。祝你使用愉快。","link":"/%E7%99%BD%E5%AB%96jsDelivr%E4%BD%9C%E4%B8%BA%E8%87%AA%E5%B7%B1%E7%BD%91%E7%AB%99%E7%9A%84cdn/"}],"tags":[],"categories":[{"name":"操作系统","slug":"操作系统","link":"/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"网络","slug":"网络","link":"/categories/%E7%BD%91%E7%BB%9C/"},{"name":"闲聊","slug":"闲聊","link":"/categories/%E9%97%B2%E8%81%8A/"},{"name":"Git","slug":"Git","link":"/categories/Git/"},{"name":"鸡汤","slug":"鸡汤","link":"/categories/%E9%B8%A1%E6%B1%A4/"},{"name":"C++","slug":"C","link":"/categories/C/"}]}